# hw4
> Applying Deep Learning to the Cache Replacement Problem

## 问题描述
文章主要研究如何将深度学习的方法应用到缓存替换问题乃至整个计算机体系结构领域。  

传统的cache替换算法通常基于固定的规则或启发式策略，而深度学习可以通过学习数据的模式和特征来自动调整缓存替换策略，从而提高缓存性能。  
但深度学习的模型很难部署到硬件预测器上，作者希望通过从多层神经网络中获取灵感来设计相应的特征表示，从而制作性能相当但更简单、适合部署到硬件中的感知机模型。


## 论文贡献
1. 第一个提出了**使用深度学习来帮助设计**硬件cache置换策略。
2. 提出了一个基于attention的LSTM模型，显著提高了cache预测准确度并且可以通过注意力机制进行**解释**。通过对模型进行消融实验，得到以下结论：
   - 过去一段PC访问历史(30条)让模型性能提高很多
   - 模型只需要几条指令就达到较好的准确率
   - 预测精度在很大程度上与序列顺序无关
3. 使用从LSTM模型中获取的灵感，设计了**准确率与LSTM模型相当**，但比其简单很多的SVM模型
4. 最终形成了整体的cache置换策略Glider，**性能胜过了当前最佳cache置换策略**。
5. 作者设计Glider的整个过程可以作为一个**通用的框架**，将深度学习结合专业领域知识，从而设计出更好的硬件预测器。


## 论文优点
1. 文章创新性地**使用深度学习来指导硬件cache置换策略的设计**，通过实验和注意力机制来挖掘模型的内在规律，从而可以找到更重要的特征，去除不必要的特征，设计更适合硬件的模型。
2. 论文设计Glider的整个过程思路清晰，可以作为一个**通用的框架**，在设计其他的硬件预测器时结合深度学习来挖掘特征和特征表示。
3. 论文设计的模型充分考虑到**硬件部署的可行性**，在性能与LSTM模型接近的基础上，较大程度的降低了硬件预算和训练开销。


## 论文缺点
1. 不需要使用RNN结构，可以完全基于注意力机制构建深度学习模型(transformer: attention is all you need)，效果和可解释性可能会更好。
2. 最终的Glider策略模型所占空间时Hawkeye的两倍(需要记录众多ISVM权重信息)，计算代价是8倍，这个开销较大，可以考虑进一步优化特征表示。
3. 文章最后提到，深度学习模型可以挖掘高级程序语义信息来判断哪些消息是缓存友好的，但是并没有进一步考虑如何投入硬件应用。


## 改进思路
1. 尝试使用transformer等模型，拥有更好的**捕捉上下文信息能力**，同时关注每个注意力头的注意权重能提供更好的可解释性，也许能从中挖掘更多信息以设计特征。
2. **利用深度学习模型挖掘高级程序语义信息**，与编译器等阶段协作，在程序中插入特定提示指令，让硬件感知到语义信息进而做出更好的预测。
3. 优化特征表示后可以尝试决策树等模型，适当简化模型结构，以减少硬件预算和训练开销。
